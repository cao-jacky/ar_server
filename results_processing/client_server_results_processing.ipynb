{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mmap\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\boldmath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching through server logs\n",
    "server_log_folder = \"../logs_server/logs\"\n",
    "server_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(server_log_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            server_folder_files.append(os.path.join(r, file))\n",
    "\n",
    "server_log_files = []\n",
    "            \n",
    "for curr_file in server_folder_files:\n",
    "    cf_orig = curr_file\n",
    "    curr_file = curr_file.split(\"/\")[3].split(\"_\")\n",
    "    \n",
    "    cf_type = curr_file[0]\n",
    "    cf_time = curr_file[1].split(\".txt\")[0]\n",
    "    \n",
    "    cft_obj = datetime.strptime(cf_time, '%Y-%m-%d %H:%M:%S')\n",
    "    cft_unix = cft_obj.timestamp()\n",
    "    \n",
    "    file_info = [cft_unix, cf_orig]\n",
    "\n",
    "    globals()[\"server_log_files\"].append(file_info)\n",
    "    \n",
    "############################\n",
    "    \n",
    "# Searching through device logs \n",
    "device_logs_folder = \"../logs_devices/\"\n",
    "devices_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(device_logs_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            devices_folder_files.append(os.path.join(r, file))\n",
    "            \n",
    "devices_log_files = []\n",
    "            \n",
    "for curr_file in devices_folder_files:\n",
    "    cf_orig = curr_file\n",
    "    curr_file = curr_file.split(\"/\")[-1].split(\"_\")\n",
    "    cf_time = float(curr_file[1].split(\".txt\")[0]) / 1000\n",
    "    \n",
    "    file_info = [str(cf_time), cf_orig]\n",
    "    globals()[\"devices_log_files\"].append(file_info)\n",
    "    \n",
    "# sort by unix_timestamp\n",
    "server_log_files = sorted(server_log_files, key=operator.itemgetter(0))\n",
    "devices_log_files = sorted(devices_log_files, key=operator.itemgetter(0))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    # Returning nearest value and index\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx], idx\n",
    "\n",
    "def frames_finder_device(file_name):\n",
    "    file_frames = []\n",
    "    with open(file_name) as search:\n",
    "        for line in search:\n",
    "            line = line.rstrip()  # remove '\\n' at end of line\n",
    "            if \"sent with size\" in line:\n",
    "                frame_no = int(re.findall(r'frame(.+?)sent with size', line)[0])\n",
    "                file_frames.append(frame_no)         \n",
    "    return file_frames\n",
    "    \n",
    "def frames_finder_server(file_name):\n",
    "    file_frames = []\n",
    "    with open(file_name) as search:\n",
    "        for line in search:\n",
    "            line = line.rstrip()  # remove '\\n' at end of line\n",
    "            if \"received, filesize:\" in line:\n",
    "                frame_no = int(re.findall(r'Frame(.+?)received, filesize:', line)[0])\n",
    "                file_frames.append(frame_no)\n",
    "    return file_frames\n",
    "\n",
    "def frames_comparer(server_log, device_log):\n",
    "    device_frames = frames_finder_device(device_log)\n",
    "    server_frames = frames_finder_server(server_log)\n",
    "    \n",
    "    list_comparison = set(device_frames) & set(server_frames)\n",
    "    device_server_percent = (len(list_comparison) / len(server_frames)) * 100\n",
    "    \n",
    "    if device_server_percent > 80:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching both server and device log files to as close together as possible \n",
    "\n",
    "# extracting server log file creation time\n",
    "sl_times = [lst[:1] for lst in server_log_files]\n",
    "sl_times = np.array(sl_times)\n",
    "\n",
    "matched_logs = []\n",
    "\n",
    "for i_dl in range(len(devices_log_files)):\n",
    "    curr_dl = devices_log_files[i_dl] # curr device log\n",
    "    dl_creation = int(float(curr_dl[0])) # int time for device log creation\n",
    "    \n",
    "    # finding closest server log file\n",
    "    closest_sl = find_nearest(sl_times, dl_creation)\n",
    "    csl_time = closest_sl[0]\n",
    "    csl_index = closest_sl[1]\n",
    "    server_log_file = server_log_files[csl_index] # select the logfile\n",
    "    \n",
    "    #print([server_log_file[1], curr_dl[1]])\n",
    "    compare_logs = frames_comparer(server_log_file[1], curr_dl[1])\n",
    "    if compare_logs:\n",
    "        matched_logs.append([server_log_file[1], curr_dl[1]]) # save only logfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "code_folding": [
     47,
     53,
     57,
     61,
     64,
     68,
     73,
     79
    ]
   },
   "outputs": [],
   "source": [
    "def log_parser(server_lf, device_lf):    \n",
    "    # number of lines in file\n",
    "    with open(server_lf) as f:\n",
    "        num_lines_s = sum(1 for _ in f)\n",
    "    with open(device_lf) as g:\n",
    "        num_lines_d = sum(1 for _ in g)\n",
    "    \n",
    "    # number of frames sent from the device\n",
    "    no_frames = open(server_lf, 'r').read().count(\"received, filesize:\")\n",
    "    \n",
    "    # reading the file contents of both logs\n",
    "    contents_s = open(server_lf, \"r\").readlines()\n",
    "    contents_d = open(device_lf, \"r\").readlines()\n",
    "    \n",
    "    # storing current frame being considered\n",
    "    cf_ticker = []\n",
    "    \n",
    "    # requests\n",
    "    requests = []\n",
    "    \n",
    "    # arrays for latencies which are in units of ms\n",
    "    session_latencies = np.zeros([no_frames, 18])\n",
    "    transfer_latencies = np.zeros([no_frames, 5])\n",
    "    \n",
    "    clients = []\n",
    "    \n",
    "    cf_considered = 0\n",
    "    # looping over server log\n",
    "    for lf_line in range(num_lines_s):\n",
    "        curr_line = contents_s[lf_line] \n",
    "        \n",
    "        if not curr_line == \"\\n\":\n",
    "            cl_split = curr_line.split(\" \")\n",
    "        \n",
    "        if \"received, filesize:\" in curr_line:\n",
    "            curr_frame_no = cl_split[1]\n",
    "            file_size = cl_split[4]\n",
    "            device_ip = cl_split[-1]\n",
    "            dip_int = device_ip.replace('.', '').replace('\\n', '')\n",
    "            if dip_int not in clients:\n",
    "                clients.append(dip_int)\n",
    "            if session_latencies[cf_considered][0] == 0:\n",
    "                session_latencies[cf_considered][0] = float(curr_frame_no)\n",
    "                session_latencies[cf_considered][14] = float(dip_int)\n",
    "                session_latencies[cf_considered][17] = float(file_size)\n",
    "                \n",
    "            s_receive = float(re.search(\"at(.*)from device\", curr_line).group(1))\n",
    "            \n",
    "            # averaging multiple times together \n",
    "            sift_points = []\n",
    "            match_sift = []\n",
    "\n",
    "        if \"SIFT points extracted in time\" in curr_line:\n",
    "            sift_time = float(cl_split[-1]) * 1000\n",
    "            sift_points.append(sift_time)\n",
    "            sp_average = np.average(sift_points)\n",
    "            session_latencies[cf_considered][3] = sp_average\n",
    "\n",
    "        if \"PCA encoding time\" in curr_line:\n",
    "            pca_time = float(cl_split[-1]) * 1000\n",
    "            session_latencies[cf_considered][4] = pca_time\n",
    "\n",
    "        if \"Fisher Vector encoding time\" in curr_line:\n",
    "            fsh_time = float(cl_split[-1]) * 1000\n",
    "            session_latencies[cf_considered][5] = fsh_time\n",
    "            \n",
    "        if \"time before matching\" in curr_line:\n",
    "            tbf_timestamp = float(cl_split[-1])\n",
    "\n",
    "        if \"LSH NN searching time\" in curr_line:\n",
    "            lshnn_time = float(cl_split[-1]) * 1000\n",
    "            session_latencies[cf_considered][6] = lshnn_time\n",
    "            \n",
    "        if \"after matching\" in curr_line:\n",
    "            af_time = float(cl_split[-1])\n",
    "            fhy_time = (af_time - tbf_timestamp) * 1000\n",
    "            #session_latencies[cf_considered][7] = fhy_time\n",
    "            \n",
    "        if \"MatchSiftData time\" in curr_line:\n",
    "            msd_time = float(cl_split[-2])\n",
    "            match_sift.append(msd_time)\n",
    "            msd_average = np.average(msd_time)\n",
    "            session_latencies[cf_considered][7] = msd_average\n",
    "            \n",
    "        if \"Matching features\" in curr_line:\n",
    "            mf_percentage = float(cl_split[-2].replace('%', ''))\n",
    "            session_latencies[cf_considered][9] = mf_percentage\n",
    "            \n",
    "        # was the cache used and was it succesful\n",
    "        if \"Cache query - time before matching:\" in curr_line:\n",
    "            session_latencies[cf_considered][11] = 1\n",
    "        \n",
    "        if \"Added item to cache\" in curr_line: \n",
    "            session_latencies[cf_considered][13] = 1\n",
    "        \n",
    "        if \"res sent, marker#:\" in curr_line:\n",
    "            marker_no = float(cl_split[5])\n",
    "            session_latencies[cf_considered][10] = marker_no\n",
    "            \n",
    "            cache_query = session_latencies[cf_considered][11]\n",
    "            \n",
    "            mf_percentage = session_latencies[cf_considered][9]\n",
    "            if (cache_query) and (0 < mf_percentage < 100 ) and (marker_no == 1):\n",
    "                session_latencies[cf_considered][12] = 1\n",
    "                \n",
    "            s_send = float(cl_split[-1])\n",
    "            s_total = (s_send - s_receive) * 1000\n",
    "            session_latencies[cf_considered][15] = s_total\n",
    "            \n",
    "            cf_considered += 1\n",
    "\n",
    "#     succesful_recognitions = []\n",
    "#     succesful_cache = []\n",
    "#     # search through all the frames\n",
    "#     for i in range(len(session_latencies)):\n",
    "#         curr_frame = session_latencies[i]\n",
    "        \n",
    "#         cf_id = curr_frame[0]\n",
    "#         cf_recog = curr_frame[10]\n",
    "#         cf_cache = curr_frame[12] # cache queried\n",
    "        \n",
    "#         cf_add_cache = curr_frame[13] # item was added to cache\n",
    "        \n",
    "#         if int(cf_recog) == 1:\n",
    "#             # frame has had succesful recognition performed or cache recognition\n",
    "            \n",
    "#             if int(cf_add_cache):\n",
    "#                 succesful_recognitions.append(cf_id)\n",
    "#             else:\n",
    "#                 succesful_cache.append(cf_id)\n",
    "        \n",
    "    # Client times\n",
    "    pp_begin_uxtime = 0\n",
    "    frame_sent_ux_time = 0 \n",
    "    curr_frame_no = 0\n",
    "    curr_frame_loc = 0\n",
    "    \n",
    "    # offset of phone in seconds\n",
    "    android_offset = 0\n",
    "    \n",
    "    for lf_line in range(num_lines_d):\n",
    "        curr_line = contents_d[lf_line]\n",
    "        cl_split = curr_line.split(\" \")\n",
    "\n",
    "        if \"get gray scaled frame data at\" in curr_line:\n",
    "            c_pre_begin = float(cl_split[-1])\n",
    "        \n",
    "        if \"sent with size\" in curr_line:\n",
    "            # find frame number\n",
    "            frame_no = float(re.search(\"frame(.*)sent with size\", curr_line).group(1))\n",
    "\n",
    "            sl_where = np.where(session_latencies[:,0] == frame_no)[0]\n",
    "\n",
    "            if not sl_where.size == 0:\n",
    "                curr_frame_no = frame_no\n",
    "                curr_frame_loc = sl_where[0]\n",
    "\n",
    "                c_send = float(cl_split[-1]) \n",
    "\n",
    "                c_pre = c_send - c_pre_begin\n",
    "                session_latencies[curr_frame_loc][1] = c_pre\n",
    "\n",
    "        if \"res received at\" in curr_line:\n",
    "            c_receive = (float(cl_split[-1]) / 1000)\n",
    "\n",
    "        if \"image border created:\" in curr_line:\n",
    "            curr_date = cl_split[0]\n",
    "            curr_year = \"19\"\n",
    "\n",
    "            curr_time = cl_split[1]\n",
    "            dt_string = curr_year + \"-\" + curr_date + \" \" + curr_time\n",
    "            curr_dt = datetime.strptime(dt_string, '%y-%m-%d %H:%M:%S.%f')\n",
    "            cdt_unix = curr_dt.timestamp()\n",
    "            \n",
    "            # time from client sending to client receiving\n",
    "            c_send_receive = (c_receive - (c_send/1000)) * 1000\n",
    "            \n",
    "            # total data transfer times \n",
    "            data_transfer = c_send_receive - session_latencies[curr_frame_loc][15]\n",
    "            dt_fraction = session_latencies[curr_frame_loc][17] / (session_latencies[curr_frame_loc][17] + 512)\n",
    "            data_transfer = dt_fraction * data_transfer\n",
    "            \n",
    "            session_latencies[curr_frame_loc][2] = data_transfer\n",
    "\n",
    "            # post-processing time\n",
    "            c_post = cdt_unix - c_receive\n",
    "            session_latencies[curr_frame_loc][8] = c_post * 1000\n",
    "            \n",
    "            c_total = c_pre + c_post\n",
    "            session_latencies[curr_frame_loc][16] = c_total\n",
    "                 \n",
    "    #print(session_latencies)\n",
    "    return session_latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "code_folding": [
     56,
     58
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.83822495  32.68839567  52.97620812  31.26283836  62.77677069\n",
      "          nan  19.90268033  73.29717297  37.05594179  30.75491691\n",
      "  28.37589339  34.976663    22.53490194  33.2977092   47.50320744\n",
      "  23.23235103  30.5290188   32.80302766  49.20642142  35.05279835\n",
      "  21.16659833  28.43397167  39.98467946  39.93753466  40.24420631\n",
      "  23.90713483  37.65610081  40.45853921  34.69830819 114.77732751\n",
      "  45.98205175  23.24866773  39.89096259  23.94734959  33.34366417\n",
      "  18.22588756  40.93930127  28.67647957  38.33847089  30.33701964\n",
      "  33.3993731   24.25470461  36.94671833  38.46860197  24.34968205\n",
      "  27.98774454  34.25162866  36.34744135  33.19418513  39.22353835\n",
      "  36.41290107  35.63457788          nan          nan  50.15488613\n",
      "  22.88226182  55.89284917  38.1549594   50.5460201   35.31549217\n",
      "  34.43377931  34.30594508  53.12312867  37.74979317          nan\n",
      " 105.09524588   6.54240875          nan          nan          nan\n",
      "          nan          nan  74.78079311  12.6664947  160.44293375\n",
      "  30.79950822 110.59191189 108.53714695  35.83435585  95.13745091\n",
      " 104.10068609  78.87323622 112.49876199  34.65293131          nan\n",
      "          nan          nan          nan          nan          nan\n",
      " 115.88902225  31.94448974 108.45100435  29.20508942  89.93080065\n",
      "  41.32604939 103.65339845  30.3235141   97.98305175  31.45585599\n",
      " 130.16389827  36.25718185 103.5198465   25.4559716   98.68317679\n",
      " 104.68618502 102.95065895  27.40412522 104.24529379 126.10398291\n",
      "  33.54845164  99.48426745  31.69199474 104.42513677  36.71946222\n",
      "          nan          nan          nan 103.52109008          nan\n",
      " 112.27974122 108.36437477  35.72591793  41.61559723  97.6177723\n",
      " 102.1034385  104.02748392  98.5266266   31.48528569  91.66369488\n",
      " 108.37779238  35.13781661  34.60907554  32.83406703  99.0296753\n",
      "  35.7721265 ]\n",
      "(130,) 6.0\n",
      "Client pre-processing: 11.0 +- 3.1112413093823337\n",
      "(114,) 6.542408749349005\n",
      "Data transfer: 36.83309027582865 +- 31.675115574786044\n",
      "(133,) 0.793933868408203\n",
      "SIFT feature extraction: 2.01296806335449 +- 0.4889050416196107\n",
      "(6,) 1.70803070068359\n",
      "PCA dimension reduction: 1.7970800399780251 +- 0.12075351848208897\n",
      "(131,) 1.18184089660645\n",
      "FV encoding with GMM: 1.61600112915039 +- 0.13331441747818848\n",
      "(6,) 2.69794464111328\n",
      "LSH NN searching: 2.7985572814941397 +- 0.530257588607872\n",
      "(134,) 0.06\n",
      "Template matching: 0.13 +- 0.0363527064924335\n",
      "(109,) 9.000062942504883\n",
      "Client post-processing: 17.000198364257812 +- 3.8822846672523994\n",
      "Overall latency: 73.18789515406351 +- 3.8822846672523994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacky/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "# parsing matched server and client log files to extract latencies\n",
    "\n",
    "results_array = np.zeros([1,18])\n",
    "\n",
    "counter = 1\n",
    "for i in range(len(matched_logs)):\n",
    "    curr_logs = matched_logs[i]\n",
    "\n",
    "    curr_server_log = curr_logs[0]\n",
    "    curr_device_log = curr_logs[1]\n",
    "    \n",
    "    results = log_parser(curr_server_log, curr_device_log)\n",
    "    \n",
    "#     if counter == len(matched_logs):\n",
    "#         print(curr_server_log, curr_device_log)\n",
    "#         results_array = np.append(results_array, results, axis=0)\n",
    "        \n",
    "    results_array = np.append(results_array, results, axis=0)\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "results_array = results_array[~np.all(results_array == 0, axis=1)]\n",
    "results_array[results_array == 0] = np.nan\n",
    "\n",
    "tasks = {\n",
    "    1 : \"Client pre-processing: \",\n",
    "    2 : \"Data transfer: \",\n",
    "    3 : \"SIFT feature extraction: \",\n",
    "    4 : \"PCA dimension reduction: \",\n",
    "    5 : \"FV encoding with GMM: \",\n",
    "    6 : \"LSH NN searching: \",\n",
    "    7 : \"Template matching: \",\n",
    "    8 : \"Client post-processing: \"\n",
    "}\n",
    "\n",
    "# print(\"\")\n",
    "\n",
    "print(results_array[:,2])\n",
    "    \n",
    "overall_latency_med = 0\n",
    "overall_latency_std = 0\n",
    "for i in range(len(results_array[:,0])):\n",
    "    curr_index = i + 1 \n",
    "    if curr_index <= len(tasks):\n",
    "        curr_col = results_array[:,curr_index]\n",
    "        \n",
    "        # removing outliers\n",
    "        curr_col = curr_col[abs(curr_col - np.nanmean(curr_col)) < 2 * np.nanstd(curr_col)]\n",
    "        print(np.shape(curr_col), np.min(curr_col))\n",
    "        \n",
    "        med_val = np.nanmedian(curr_col)\n",
    "        std_val = np.nanstd(curr_col)\n",
    "\n",
    "        overall_latency_med += med_val\n",
    "        overall_latency_std += std_val\n",
    "\n",
    "        print(tasks[curr_index] + str(med_val) + \" +- \" + str(std_val))\n",
    "\n",
    "print(\"Overall latency: \" + str(overall_latency_med) + \" +- \" + str(std_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
